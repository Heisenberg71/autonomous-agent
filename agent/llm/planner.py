import json

def initiate_planner(user_query: str) -> dict:
    """
    Generates a tool usage plan for the given user query by identifying which tool 
    should be used and extracting the necessary arguments for that tool.

    The function prompts a language model to analyze the user's query and decide 
    which tool is appropriate based on the query content. It supports tools such as:
    - Calculator (for math calculations)
    - Weather (for weather information)
    - Knowledge Base (for querying stored information)
    - Currency Converter (for currency conversion)
    - No Tools (if the query can be answered directly without tools)

    For each tool, the function expects the language model to return a JSON-formatted 
    plan specifying the tool name and its required arguments.

    Args:
        user_query (str): The user's input query or request.

    Returns:
        str: A JSON string representing the planned tool to be used and its arguments, 
             as generated by the language model.

    Example response formats:
        {"tool": "calculator", "args": {"operand": "%", "operator_1": 12.5, "operator_2": 243}}
        {"tool": "weather", "args": {"city": "dhaka", "from_date": "2025-08-17", "to_date": "2025-08-23"}}
        {"tool": "knowledge_base", "args": {"query": "summarize user prompt"}}
        {"tool": "currency_converter", "args": {"from_currency": "USD", "to_currency": "EUR", "amount": 100}}

    Note:
        The response should contain no additional information other than the JSON plan.
    """

    system_prompt = """You are a tool planner for an autonomous agent.
    Available tools:
    1. Calculator - For math calculations
        if the query is about math, return a plan with tool "calculator",
        extract the value of operand, operator_1 and operator_2 from user prompt, 
        and return like the example below:
        
        Example response: {"tool": "calculator","args": {"operand": "%","operator_1": 12.5,"operator_2": 243}}
        Do not return any other information in the plan.

    2. Weather - For weather information
        if the query is about weather, return a plan with tool "weather",
        extract the value of city, from_date and to_date from user prompt, 
        and return like the example below:
        
        Example response: {"tool": "weather", "args": {"city": "dhaka", "from_date": "2025-08-17", "to_date": "2025-08-23"}}
        Do not return any other information in the plan.

    3. Knowledge Base - For querying stored information
        if the query is about knowledge base, return a plan with tool "knowledge_base",
        take user prompt and summarize it as a search query and put it in args dictionary with key "query", 
        and return like the example below:
        
        Example response: {"tool": "knowledge_base", "args": {"query": "summazrize user prompt"}}
        Do not return any other information in the plan.

    4. Currency Converter - For currency conversions
        if the query is about currency conversion, return a plan with tool "currency_converter",
        extract the value of from_currency, to_currency and amount from user prompt, 
        and return like the example below:
        
        Example response: {"tool": "currency_converter", "args": {"from_currency": "USD", "to_currency": "EUR", "amount": 100}}
        Do not return any other information in the plan.

    5. No Tools - If the query can be answered directly without tools
    """

    return ask_to_llm(system_prompt, user_query)

def call_llm_with_knowledge_base(user_query, knowledge_base)  -> dict:
    """
    Generates a response to the user's query by leveraging a provided knowledge base.

    This function constructs a system prompt instructing the language model to use 
    the knowledge base when answering the user's question, then calls the LLM 
    interface function `ask_to_llm` to generate the response.

    Args:
        user_query (str): The question or prompt provided by the user.
        knowledge_base (str): The textual knowledge base or context to be used by the LLM.

    Returns:
        str: The response generated by the language model based on the user query 
        and knowledge base.
    """

    system_prompt = """You are a helpful assistant. Use the knowledge base to answer the question.
    you are given a prompt and a knowledge base. generate a response based on the knowledge base.
    """

    return ask_to_llm(system_prompt, user_query, knowledge_base)

def find_top_matched_titles(user_query, titles)  -> dict:
    """
    Identifies the top 3 most relevant titles from a list based on the user's query.

    This function simulates a language model call that takes a user prompt and a list 
    of titles, then returns a JSON-formatted response containing the three titles 
    most relevant to the prompt.

    Args:
        user_query (str): The user's input query or prompt.
        titles (list of str): A list of titles to match against the query.

    Returns:
        str: A JSON string with a key "top_matched_titles" mapping to a list of up to 
             three titles most relevant to the user's query.

    Example response:
        {"top_matched_titles": ["Alan Turing", "Ada Lovelace"]}
    """

    system_prompt = """You are a helpful assistant. You are given a prompt and a list of titles.
    Find the 3 most relevant titles that match the prompt.

    Example response: {"top_matched_titles": ["Alan Turing", "Ada Lovelace"]}
        Do not return any other information in the plan.
    """
    
    return ask_to_llm(system_prompt, user_query, titles)

def ask_to_llm(system_prompt, user_query, knowledge_base=None) -> dict:
    """
    Simulates a call to a language model by taking a system prompt, user query,
    and optionally a knowledge base, then returning a predetermined response.

    This is a stub function intended to mock the behavior of a real LLM API call.
    It ignores the inputs and returns a fixed response for demonstration purposes.

    Args:
        system_prompt (str): The instruction or context provided to the language model.
        user_query (str): The user's input query or prompt.
        knowledge_base (optional, any): Additional contextual information to assist the model.

    Returns:
        dict: A simulated response, here returning a fixed dictionary representing a 
              currency conversion tool plan.
    """

    # Uncomment the line below to simulate a currency conversion tool response
    # return {"tool": "currency_converter", "args": {"from_currency": "USD", "to_currency": "EUR", "amount": 100}}
    
    # Uncomment the lines below to simulate a weather tool response    
    # if(knowledge_base == None):
    #     return {"tool": "weather", "args": {"city": "dhaka", "from_date": "2025-08-17", "to_date": "2025-08-23"}}
    # return "The weather is sunny with a high of 25°C and a low of 15°C."

    # Uncomment the line below to simulate a calculator tool response
    return {"tool": "calculator","args": {"operand": "%","operator_1": 12.5,"operator_2": 243}}
    
    # Uncomment the line below to simulate a knowledge base tool response
    # return {"top_matched_titles": ["Alan Turing"]}